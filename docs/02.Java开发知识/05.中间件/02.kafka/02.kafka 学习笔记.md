---
title: kafka 学习笔记
url: https://www.yuque.com/weishengcc/hi3vv4/cs8iiw8l9lz3rq9r
date: 2023-01-09 09:39:04
permalink: /pages/992452/
categories: 
  - Java开发知识
  - 05中间件
  - kafka
tags: 
  - 
author: 
  name: SSF
  link: https://github.com/SSFsystem
---

<a name="ujZni"></a>

# 一: 推荐资料

1. 《深入理解Kafka：核心设计与实践原理 》
2. [Kafka核心知识整理 | ProcessOn免费在线作图,在线流程图,在线思维导图](https://www.processon.com/view/link/624d3c2bf346fb57dbebfd1b) <a name="GSB1O"></a>

# 二: 入门

<a name="vVXmH"></a>

## 1-基础入门

<a name="ni81W"></a>

### kafka 是如何工作的

Kafka是一个分布式系统，由通过高性能[TCP网络协议](https://kafka.apache.org/protocol.html)进行通信的**服务器**和**客户端**组成。它可以部署在本地和云环境中的裸机硬件、虚拟机和容器上。
**服务器:  **Kafka作为一个或多个服务器的集群运行,可以设置备份与功能分化,具有高度可扩展性和容错能力
**客户端: **允许你编写分布式应用程序和微服务，这些应用程序和微服务以并行、大规模和容错方式读取、写入和处理事件流， <a name="XIaea"></a>

### 主要概念和术语

![](1648451060192-d796ab9b-abb4-41b5-b3b7-922995aaf323.jpeg)
**事件:  **记录发生了某事的事实,事件具有 `键``值` `时间戳`和 可选的元数据标头
**Producer（生产者): **向Kafka 发布（写入）事件的客户端应用程序
**Consumer（消费者):**订阅（读取和处理）这些事件的客户端应用程序
**Consumer Group（消费者组）** ：多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
**Broker（代理）** : 可以看作是一个独立的 Kafka 实例，负责处理客户端请求以及对消息持久化。

> 在kafka中生产者和消费者是完全解耦的,彼此不可知

每个 **Broker** 中又包含了 **Topic **以及 **Partition **这两个重要的概念：
**Topic（主题）** : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic 来消费消息。
**Partition（分区）** : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。
事件被组织并持久的存储在**主题**中,`主题`支持零或多个 生产者和写入者,即兼容通道模式.**主题**中的数据在使用后不会被删除,可以通过每个主题的配置设置定义 Kafka 应将事件保留多长时间.

> Kafka的性能在数据大小方面实际上是恒定的，因此长时间存储数据是完全可以的。

主题是**分区**的,意味数据具有容错能力和高可用性

<a name="myzHh"></a>

### 操作部署

通过docker-compose.yml,执行   docker-compose  up运行
访问  kafka-manager  图形化管理界面对kafka进行设置

```yaml
version: '3'
services:
  zookepper:
    image: wurstmeister/zookeeper                    # 原镜像`wurstmeister/zookeeper`
    container_name: zookeeper                        # 容器名为'zookeeper'
    volumes:                                         # 数据卷挂载路径设置,将本机目录映射到容器目录
      - "/etc/localtime:/etc/localtime"
    ports:                                           # 映射端口
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka                                # 原镜像`wurstmeister/kafka`
    container_name: kafka                                    # 容器名为'kafka'
    volumes:                                                 # 数据卷挂载路径设置,将本机目录映射到容器目录
      - "/etc/localtime:/etc/localtime"
    environment:                                                       # 设置环境变量,相当于docker run命令中的-e
      KAFKA_BROKER_ID: 0                                               # 在kafka集群中，每个kafka都有一个BROKER_ID来区分自己
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://ip:9092 # TODO 将kafka的地址端口注册给zookeeper
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092                        # 配置kafka的监听端口
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181                
      KAFKA_CREATE_TOPICS: "hello_world"
    ports:                              # 映射端口
      - "9092:9092"
    depends_on:                         # 解决容器依赖启动先后问题
      - zookepper

  kafka-manager:
    image: sheepkiller/kafka-manager                         # 原镜像`sheepkiller/kafka-manager`
    container_name: kafka-manager                            # 容器名为'kafka-manager'
    environment:                        # 设置环境变量,相当于docker run命令中的-e
      ZK_HOSTS: zookeeper:2181 
      APPLICATION_SECRET: xxxxx
      KAFKA_MANAGER_AUTH_ENABLED: "true"  # 开启kafka-manager权限校验
      KAFKA_MANAGER_USERNAME: admin       # 登陆账户
      KAFKA_MANAGER_PASSWORD: 123456      # 登陆密码
    ports:                              # 映射端口
      - "9000:9000"
    depends_on:                         # 解决容器依赖启动先后问题
      - kafka
```

<a name="FaLJ3"></a>

## 2:常用操作:

<a name="BQwaO"></a>

### kafka 应用程序接口

除了用于管理任务的命令行工具外，Kafka 还有五个用于 Java 和 Scala 的核心 API：

1. [Producer API](https://kafka.apache.org/documentation/#producerapi) :用于将事件流发布（写入）到一个或多个 Kafka 主题
2. [Consumer API](https://kafka.apache.org/documentation/#consumerapi) :用于订阅（读取）一个或多个主题并处理向其生成的事件流
3. [Streams API](https://kafka.apache.org/32/documentation/streams) : 用于实现流处理应用程序和微服务api
4. [Connect API](https://kafka.apache.org/documentation/#connectapi) : 用于构建和运行可重用的数据导入/导出连接器 (不需要自己实现 ,kafka社区意见提供了很多连接器)
5. [Admin API](https://kafka.apache.org/documentation/#adminapi) : 用于管理和检查主题、代理和其他 Kafka 对象

<a name="DBiot"></a>

# 三: 热门知识点

<a name="HjF2Z"></a>

## 如何保证顺序消费

经常有业务场景需要严格保证消息的消费顺序,例如修改会员等级与根据会员等级这两个操作对顺序性要求就严格.
Kafka 中 **Partition(分区)**是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的 **Partition(分区)** 又存在于 **Topic(主题) **这个概念中，并且我们可以给特定 Topic 指定多个 **Partition**,多个分区可以存在不同的**Broker**中
这就导致**kafka**可以保证**Partition(分区)**中消息的顺序性,不能保证** Topic(主题) **中的** Partition(分区)** 的有序

> 消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。

![](1623850209944-c6d54675-be87-4e88-a862-e5eea11c021c.png) <a name="hmmhM"></a>

### 解决措施(需求是要求强一致):

Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。
**最终一致:**

1. 1 个 Topic 只对应一个 Partition。
2. **单处理:**发送消息时指定key/Partition,() (推荐)

**最终一致:**

1. **宽表: **将每一个订单状态，单独分出一个或多个独立的字段。消息来时只更新对应的字段就好，消息只会存在短暂的状态不一致问题，但是状态最终是一致的
2. **消息补偿机制：**另一个进行消费相同topic的数据，消息落盘，延迟处理。将消息与DB进行对比，如果发现数据不一致，再重新发送消息至主进程处理
3. **单处理:**只需要把相同userId/orderId发送到相同的partition（因为一个partition由一个Consumer消费），又能解决大部分消费顺序的问题()

<a name="eouD0"></a>

## 消费者组与重平衡

多个消费者实例组成消费者组,Kafka 以 Consumer Group 这一个**整体**来订阅 Topic （主题） ，Consumer Group 内的所有 Consumer 共同来消费订阅的 Topic 内的所有  Partition（分区）。可以创建多个消费者组订阅同一主题来进行同一消息的重复消费.

Kafka 通过 Group ID（字符串） 唯一标识 Consumer Group 。

并且，Topic 下的每个 Partition 只从属于 Consumer Group 中的一个 Consumer，**不可能出现 Consumer Group 中的两个 Consumer 负责同一个 Partition**。
如果消费者组内数量大于主题分区,就会有消费者空闲,因此一般建议消费者组内**消费者数量**等于**主题数量**

> 重平衡:假如消费者组的数量发生变化呢,就会触发Rebalance

**什么是 Rebalance 呢？** Rebalance 翻译过来就是 **重平衡** ，它本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致来分配订阅 Topic 的每个分区。比如某个 Consumer Group 下有 3 个 Consumer，它订阅了 3 个 Topic，总共 6个 Partition 。正常情况下，Kafka 平均会为每个 Consumer 分配 2 个 **分区**。这个分配的过程就叫 Rebalance。

除了 Consumer Group 的 Consumer 发生变化时会发生 Rebalance，下面这些情况也会发生 Rebalance：

- 订阅的 Topic 内的 Partition 发生变更
- 订阅的 Topic 发生变更

<a name="SxJm3"></a>

## 如何保证数据不丢失

丢失消息有 3 种不同的情况，针对每一种情况有不同的解决方案。

1. 生产者丢失消息的情况
2. 消费者丢失消息的情况
3. Kafka 弄丢了消息 <a name="p7Tjv"></a>

### 生产者丢失消息的情况

生产者(Producer) 调用send方法发送消息之后，消息可能因为网络问题并没有发送过去。所以，我们不能默认在调用 send() 方法发送消息之后消息消息发送成功了。&#x20;
为了确定消息是发送成功，我们要判断消息发送的结果。&#x20;
但是，要注意的是 Producer 使用 send() 方法发送消息实际上是异步的操作，我们可以通过 get()方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：&#x20;
但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下：&#x20;
如果消息发送失败的话，我们检查失败的原因之后重新发送即可！&#x20;
另外，这里推荐为 Producer 的 retries（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了 <a name="oT5nD"></a>

### 消费者丢失消息的情况

我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。offset 表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。

当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。&#x20;
这种情况的解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。 <a name="KKzJh"></a>

### Kafka 弄丢了消息

我们知道 Kafka 为 Partition 引入了多副本（Replica）机制。Partition 中的多个副本之间会有一个叫做 Leader 的家伙，其他副本称为 Follower。我们发送的消息会被发送到 Leader 副本，然后 Follower 副本才能从 Leader 副本中拉取消息进行同步。生产者和消费者只与 Leader 副本交互。你可以理解为其他副本只是 Leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。&#x20;
试想一种情况：假如  Leader 副本所在的 Broker 突然挂掉，那么就要从 Fllower 副本重新选出一个  Leader ，但是  Leader 的数据还有一些没有被 Follower 副本的同步的话，就会造成消息丢失。 <a name="KXO3u"></a>

#### 设置 acks = all

解决办法就是我们设置  acks = all。acks 是 Kafka 生产者(Producer)  很重要的一个参数。&#x20;
acks 的默认值即为1，代表我们的消息被leader副本接收之后就算被成功发送。当我们配置 acks = all 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高. <a name="xGokz"></a>

#### 设置 replication.factor >= 3

为了保证 Leader 副本能有 Follower 副本能同步消息，我们一般会为 Topic 设置 replication.factor >= 3。这样就可以保证每个 Partition 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。 <a name="ZxPgX"></a>

#### 设置 min.insync.replicas > 1

一般情况下我们还需要设置 min.insync.replicas> 1 ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。min.insync.replicas 的默认值为 1 ，在实际生产中应尽量避免默认值 1。&#x20;
但是，为了保证整个 Kafka 服务的高可用性，你需要确保 replication.factor > min.insync.replicas 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 replication.factor = min.insync.replicas + 1。 <a name="qxU4g"></a>

#### 设置 unclean.leader.election.enable = false

Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false&#x20;
我们最开始也说了我们发送的消息会被发送到 Leader 副本，然后 Follower 副本才能从 Leader 副本中拉取消息进行同步。多个 Follower 副本之间的消息同步情况不一样，当我们配置了 unclean.leader.election.enable = false 的话，当 Leader 副本发生故障时就不会从 Follower 副本中和 Leader 同步程度达不到要求的副本中选择出 Leader ，这样降低了消息丢失的可能性。&#x20;
Reference

- Kafka 官方文档：<https://kafka.apache.org/documentation/>
- 极客时间—《Kafka 核心技术与实战》第 11 节：无消息丢失配置怎么实现？


## kafka如何保证高可用
