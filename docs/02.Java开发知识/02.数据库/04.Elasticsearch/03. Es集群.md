## 搭建
为了便捷测试,使用的是docker 部署,可以单个容器启动,也可以直接容器组启动:
下面的例子是容器组启动
> 启动命令: docker-compose up

**docker-compose.yml配置文件**
```yml
version: "3"

services:

  es-master:

    image: elasticsearch:7.4.2

    container_name: es-master

    environment:

      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

    ulimits:

      memlock:

        soft: -1

        hard: -1

      nofile:

        soft: 65536

        hard: 65536

    ports:

      - "9200:9200"

      - "9300:9300"

    volumes:

      - C:\projectSpace\Docker-compose\elasticsearch\data\es1\config/es.yml:/usr/share/elasticsearch/config/elasticsearch.yml

      - C:\projectSpace\Docker-compose\elasticsearch\data\es1\data:/usr/share/elasticsearch/data

      - C:\projectSpace\Docker-compose\elasticsearch\data\es1\log:/usr/share/elasticsearch/log

    networks:

      - net-es

  es-node1:

    image: elasticsearch:7.4.2

    container_name: es-node1

    environment:

      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

    ulimits:

      memlock:

        soft: -1

        hard: -1

      nofile:

        soft: 65536

        hard: 65536

    ports:

      - "9201:9200"

      - "9301:9300"

    volumes:

      - C:\projectSpace\Docker-compose\elasticsearch\data\es2\config/es.yml:/usr/share/elasticsearch/config/elasticsearch.yml

      - C:\projectSpace\Docker-compose\elasticsearch\data\es2\data:/usr/share/elasticsearch/data

      - C:\projectSpace\Docker-compose\elasticsearch\data\es2\log:/usr/share/elasticsearch/log

    networks:

      - net-es

  es-node2:

    image: elasticsearch:7.4.2

    container_name: es-node2

    environment:

      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

    ulimits:

      memlock:

        soft: -1

        hard: -1

      nofile:

        soft: 65536

        hard: 65536

    ports:

      - "9202:9200"

      - "9302:9300"

    volumes:

      - C:\projectSpace\Docker-compose\elasticsearch\data\es3/config/es.yml:/usr/share/elasticsearch/config/elasticsearch.yml

      - C:\projectSpace\Docker-compose\elasticsearch\data\es3/data:/usr/share/elasticsearch/data

      - C:\projectSpace\Docker-compose\elasticsearch\data\es3/log:/usr/share/elasticsearch/log

    networks:

      - net-es

networks:

  net-es:

    driver: bridge
```

**容器挂载目录下的配置文件**
```yml
# master主节点配置
# 集群名称
cluster.name: es-cluster
# 节点名称
node.name: es-master
node.master: true
node.data: true
# 网络
network.host: es-master
http.port: 9200
transport.tcp.port: 9300
http.cors.enabled: true
http.cors.allow-origin: "*"
discovery.zen.ping.unicast.hosts: ["es-master:9300", "es-node1:9300", "es-node2:9300"]
# 最少节点
discovery.zen.minimum_master_nodes: 2
discovery.zen.ping_timeout: 5s
bootstrap.memory_lock: true
action.destructive_requires_name: true
cluster.initial_master_nodes: ["es-master"]

# 子节点配置
cluster.name: es-cluster
node.name: es-node1
node.master: false
node.data: true
network.host: es-node1
http.port: 9200
transport.tcp.port: 9300
http.cors.enabled: true
http.cors.allow-origin: "*"
discovery.zen.ping.unicast.hosts: ["es-master:9300", "es-node1:9300", "es-node2:9300"]
discovery.zen.minimum_master_nodes: 2
discovery.zen.ping_timeout: 5s
bootstrap.memory_lock: true
action.destructive_requires_name: true
cluster.initial_master_nodes: ["es-master"]


```


## 集群配置
### 集群配置优先级

集群配置存在优先级问题
1. 临时集群配置
2.  持久化集群配置
3. elasticsearch.yml配置文件

### elasticsearch.yml配置文件-范例

```
cluster.name: es-application #集群名称，要求唯一  
node.name: node-1 #节点名称  
path.data: /data/elasticsearch #数据存储路径  
path.logs: /var/log/elasticsearch #日志路径  
network.host: 192.168.81.210,127.0.0.1 #对外暴露的地址  
http.port: 9200 #端口号  
discovery.zen.ping.unicast.hosts: [“192.168.81.210”, “192.168.81.220”] #主节点要配置上集群各节点ip地址，从节点配置的时候只写上主节点的ip和自己节点的ip即可  
discovery.zen.minimum_master_nodes: 1 #允许master的数量  
http.cors.enabled: true  
http.cors.allow-origin: “*”
```

## 集群常用操作命令



#### 查看集群健康状态(cluster health API)

> $ curl -X GET "http://127.0.0.1:9200/_cluster/health?pretty"


**api参数**
| 字段名称                            | 字段含义                                                                          |
|---------------------------------|-------------------------------------------------------------------------------|
| level                           | 值可以为cluster、indices、shards，用于返回不同层次的健康状况信息，默认为cluster。                        |
| wait_for_status                 | 值可以为green、yellow、red，此参数代表等待集群的状态变为指定的状态或者超时返回。                               |
| wait_for_no_relocating_shards   | true/fasle,代表是否等待不存在relocating的分片时返回，默认false。                                 |
| wait_for_no_initializing_shards | true/fasle,代表是否等待不存在initializing的分片时返回，默认false。                               |
| wait_for_active_shards          | 数值，代表等待多少个分片活跃时存活，默认为0，all代表等待所有的分片都为活跃的情况下返回。                                |
| wait_for_nodes                  | 数值，等待指定个数(记为N)的节点可达后返回，可以为**>=N,<=N,>N,<N**,也可以对应使用ge(N),le(N),gt(N),lt(N)    |
| wait_for_events                 | 给定一个优先级，等待指定优先级的所有队列事件被处理后返回。指定的优先级可为immediate,urgent,high,normal,low,languid |
| timeout                         | 当使用wait_for_XXX参数时，指定的超时时间,默认为30s                                             |
| master_timeout                  | 连接master节点的超时时间，如果没有设置，则与timeout保持一致。                                         |
| local                           | true/false，true代表从本地节点获取相应的信息，false代表从master节点获取信息，默认为false。                  |

**返回参数**
| 字段名称                             | 字段含义                                                                                                                                                          |
|----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|
| cluster_name                     | 集群的名称，每个集群拥有一个唯一的名称。                                                                                                                                          |
| status                           | 集群的状态，分为green,yellow,red三种，green代表集群所有的主分片和副本分片都正常运行，yellow代表所有的主分片都正常运行，但是存在未正常分配的副本分片，red代表有主分片未能正常分配。                                                      |
| timed_out                        | 本次查询是否超时，值为true/false。                                                                                                                                        |
| number_of_nodes                  | 集群拥有的节点数量。                                                                                                                                                    |
| number_of_data_nodes             | 集群拥有的数据节点的数量。                                                                                                                                                 |
| active_primary_shards            | 活动的主分片。                                                                                                                                                       |
| active_shards                    | 活动的分片。                                                                                                                                                        |
| relocating_shards                | 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。                                                                   |
| initializing_shards              | 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 initializing 状态。这通常会是一个临时事件，分片不应该长期停留在 initializing 状态。你还可能在节点刚重启的时候看到 initializing 分片：当分片从磁盘上加载后，它们会从 initializing 状态开始。 |
| unassigined_shards               | 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 red 状态，也会长期保有未分配分片（因为缺少主分片）。                                |
| number_of_pending_tasks          | 等待中的任务数量。                                                                                                                                                     |
| number_of_in_flight_fetch        | 进行中的任务数量。                                                                                                                                                     |
| task_max_waiting_in_queue_millis | 任务在队列中等待的最长时间。                                                                                                                                                |
| active_shards_percent_as_number  | 活动的分片占所有分片的比例。                                                                                                                                                |

status代表集群的状态，只有green才是集群完全健康的状态，unassigned_shards表明了有多少分片没有被分片，这是一个很重要的指标，正常情况下不应该存在未被分配的分片，number_of_pending_tasks则是等待中的任务数量，如果这个数值太大也需要特别关注。



#### 查询集群全部信息 /_cluster/stats?human&pretty'

#### 查看集群节点信息: /_cat/nodes?human&pretty'
```
[root@elasticsearch ~]# curl -XGET 'http://localhost:9200/_cat/nodes?human&pretty' 192.168.81.210 21 96 0 0.00 0.01 0.05 mdi * node-1 192.168.81.220 15 96 0 0.00 0.01 0.05 mdi - node-2 第一列显示集群节点的ip 倒数第二列显示集群节点的类型，*表示主节点，-表示工作节点，主节点也属于工作节点，只是多了一个调度的作用
```

#### 更新集群配置(cluster reroute API)
1.  **获取集群配置**
    
    获取显式设置的集群配置：
    
    ```bash
    curl -X GET "http://127.0.0.1:9200/_cluster/settings?pretty"
    ```
    
    获取默认的集群配置加上include_defaults参数:
    
    ```bash
    curl -X GET "http://127.0.0.1:9200/_cluster/settings?include_defaults=true&pretty"
    ```
    
2.  **更新集群配置**
    
    集群配置的更新分为持久化的、临时的更新，持久化的配置更新后集群重启仍然生效，临时的更新在集群重启后不生效。
    
    更新持久化配置：
    
    ```bash
    curl -X PUT "http://127.0.0.1:9200/_cluster/settings?pretty" -H 'Content-Type: application/json' -d'
    {
        "persistent" : {
            "indices.recovery.max_bytes_per_sec" : "50mb"
        }
    }
    '
    ```
    
    更新临时配置:
    
    ```bash
    curl -X PUT "http://127.0.0.1:9200/_cluster/settings?flat_settings=true&pretty" -H 'Content-Type: application/json' -d'
    {
        "transient" : {
            "indices.recovery.max_bytes_per_sec" : "20mb"
        }
    }
    '
    ```
    
3.  **重置集群配置**
    
    重置集群配置的只需要将配置项设置为null:
    
    ```bash
    $ curl -X PUT "http://127.0.0.1:9200/_cluster/settings?pretty" -H 'Content-Type: application/json' -d'
    {
        "transient" : {
            "indices.recovery.max_bytes_per_sec" : null
        }
    }
    '
    ```
    
    还可以使用通配符进行重置:
    
    ```bash
    $ curl -X PUT "http://127.0.0.1:9200/_cluster/settings?pretty" -H 'Content-Type: application/json' -d'
    {
        "transient" : {
            "indices.recovery.*" : null
        }
    }
    '
    ```




## 节点类型
生产环境建议根据机器选择不同配置的机器设置不同的角色
1. Master:集群状态管理
2. Data: 数据存储处理客户端请求 
3. Ingest: 数据处理
4. Coordinate : 复杂查询

```
%%配置参数%%
node.master
node.data
node.ingest
Coordinate 上面三样都为空

```




## 数据迁移

数据迁移有多种，但目前网上推荐的还是 `reindex` 

### reindex

#### reindex 介绍
Reindx API :支持把文档（query 指定文档，不指定则是全部）从一或多个索引（本地或远程）source导入到另外一个索引 dest

修改索引的主分片数，修改字段类型，集群内数据迁移/跨集群数据迁移可使用 reindex
reindex api 的注意事项：

1. _source必须是 enabled 对于 source index 的所有文档
2. reindex 其 dest 无法拷贝 source 索引的settings和mappings，需要自己创建dest 索引再跑reindex
3. reindex功能的底层实现原理是通过scroll方式实现的

```
跨集群 reindex
1. 修改 elasticsearch.yml 增加白名单 并且重启节点：
reindex.remote.whitelist: "otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*"
	支持ip，端口号，通配符

2. _reindex 操作
POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200",
      "username": "user",  # 没有登录验证可不填
      "password": "pass"
    },
    "index": "source",
    "query": {   # 匹配 source 中指定查询语句的文档导出
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {  # 导入到 dest 索引
    "index": "dest"
  }
}

```


#### reindex 支持参数
1. source
	1. index：指定源数据索引库，支持[]指定多个索引库
	2. slice：并行化执行reindex操作，自动并行化需要请求后 _reindex?slices=5 增加 slices
	3. max_docs：reindex 文档的最大数量
	4. remote：数据源是远程es集群
	5. query：匹配 source 中指定查询语句的文档导出
	6. sort：支持 source 的文档排序导出，配合 size
	7. `_source`:支持 source 的文档只导出指定字段
2. dest
	1. -  op_type：默认不生效
	2. -   routing：可更改导入文档的路由分片信息,值：keep 保留原文档的路由信息，discard 丢弃原文档的路由信息默认_id路由分片，= 指定新的路由信息
	3. -   routing：可更改导入文档的路由分片信息,值：keep 保留原文档的路由信息，discard 丢弃原文档的路由信息默认_id路由分片，= 指定新的路由信息
	4. -   routing：可更改导入文档的路由分片信息,值：keep 保留原文档的路由信息，discard 丢弃原文档的路由信息默认_id路由分片，= 指定新的路由信息
	5. conflicts：默认，版本冲突会中断 _reindex 进程,指定 proceed 则版本冲突不会中断，会返回冲突数量
	6. .size：限制从source导出的符合条件的文档数量
	7. script：支持脚本操作,对导出的文档做二次加工再导入

####  reindex 异步操作
reindex api 支持异步操作，执行只返回 task id
```
POST _reindex?wait_for_completion=false
查看task
GET _tasks?detailed=true&actions=*reindex
查看指定task
GET /_tasks/r1A2WoRbTwKZ516z6NEs5A:36619
取消task
POST _tasks/r1A2WoRbTwKZ516z6NEs5A:36619/_cancel

```