---
title: ElasticSearch--基础操作文档
date: 2023-01-09 09:39:04
permalink: /pages/1c1511/
categories:
  - Java开发知识
  - 05中间件
  - ElasticSearch
tags:
  - 
author: 
  name: SSF
  link: https://github.com/SSFsystem
---
# 基本概念
> 抄自且听风吟大佬的文档 [es使用文档](https://ropledata.blog.csdn.net/article/details/106834609)
> 部分内容摘自:Elasticsearch筋斗云版 蓝皮书 1.0



## Es的基础类型
| **ES** | **MySql** |
| --- | --- |
| 字段 | 列 |
| 文档 | 一行数据 |
| 类型(已废弃) | 表 |
| 索引 | 数据库 |

### 文档(Document)

1. Elasticesarch 是面向文档的,**文档是所有可搜索数据的最小单元**。ES的文档就像MySql中的一条记录，只是ES的文档会被序列化成json格式，保存在Elasticsearch中
- 这个json对象是由字段组成，字段就相当于Mysql的列，每个字段都有自己的类型（**字符串、数值、布尔、二进制、日期范围类型**）；
- 当我们创建文档时，如果不指定字段的类型，Elasticsearch会帮我们自动匹配类型；
- 每个文档都有一个ID，类似MySql的主键，咱们可以自己指定，也可以让Elasticsearch自动生成；
- 文档的json格式支持数组/嵌套，在一个索引（数据库）或类型（表）里面，你可以存储任意多的文档。
> 注意：虽然在实际存储上，文档存在于某个索引里，但是文档必须被赋予一个索引下的类型才可以。

### 类型(Type)
类型就相当于MySql里的表，我们知道MySql里一个库下可以有很多表，最原始的时候ES也是这样，一个索引下可以有很多类型，但是从6.0版本开始，type已经被逐渐废弃，但是这时候一个索引仍然可以设置多个类型，一直到7.0版本开始，**一个索引就只能创建一个类型了（_doc）**。
Elasticsearch7 去掉 tpye 概念
ES7.x 版本：URL 中的 type 参数为可选。
ES8.x 版本：不⽀持 URL 中的 type 参数

### 索引(Index)

1. 索引就相当于MySql里的数据库，它是具有某种相似特性的文档集合。反过来说不同特性的文档一般都放在不同的索引里；
2. 索引的名称必须全部是小写；
3. 在单个集群中，可以定义任意多个索引；
4. 索引具有mapping和setting的概念，mapping用来定义文档字段的类型，setting用来定义不同数据的分布。
## 节点(node)和分片(shard)
### 节点（node）
一个节点就是一个ES实例,其实本质就是一个java进程<br />节点的名称可以通过配置文件配置，或者在启动的时候使用-E node.name=ropledata指定，默认是随机分配的。建议咱们自己指定，因为节点名称对于管理目的很重要，咱们可以通过节点名称确定网络中的哪些服务器对应于ES集群中的哪些节点；
##### 节点分类

1. **Master Eligible节点**：每个节点启动后，默认就是Master Eligible节点，可以通过设置node.master: false 来禁止。Master Eligible可以参加选主流程，并成为Master节点（当第一个节点启动后，它会将自己选为Master节点）；注意：每个节点都保存了集群的状态，只有Master节点才能修改集群的状态信息。
2. **Data节点**：可以保存数据的节点。主要负责保存分片数据，利于数据扩展。
3. **Coordinating 节点**：负责接收客户端请求，将请求发送到合适的节点，最终把结果汇集到一起
 注意：每个节点默认都起到了Coordinating node的职责。 
> 一般在开发环境中一个节点可以承担多个角色，但是在生产环境中，还是设置单一的角色比较好，因为有助于提高性能。

### 分片
ES里面的索引可能存储大量数据，这些数据可能会超出单个节点的硬件限制。
**为了解决这个问题，ES提供了将索引细分为多个碎片的功能，这就是分片**。
分片有什么好处和注意事项呢？
> 1. 通过分片技术，咱们可以水平拆分数据量，同时它还支持跨碎片（可能在多个节点上）分布和并行操作，从而提高性能/吞吐量；
> 2. ES可以完全自动管理分片的分配和文档的聚合来完成搜索请求，并且对用户完全透明；
> 3. 主分片数在索引创建时指定，后续只能通过Reindex修改，但是较麻烦，一般不进行修改。


### 副本分片
为了实现高可用、遇到问题时实现分片的故障转移机制，ElasticSearch允许将索引分片的一个或多个复制成所谓的副本分片<br />副本分片有什么作用和注意事项呢？
> 1. 当分片或者节点发生故障时提供高可用性。因此，需要注意的是，副本分片永远不会分配到复制它的原始或主分片所在的节点上；
> 2. 可以提高扩展搜索量和吞吐量，因为ES允许在所有副本上并行执行搜索；
> 3. 默认情况下，ES中的每个索引都分配5个主分片，并为每个主分片分配1个副本分片。主分片在创建索引时指定，不能修改，副本分片可以修改。



# 使用
ES 是**RESTful 风格**的系统，所以我们需要先掌握**RESTful 的四个关键词：PUT（修改），POST（添加），DELETE（删除），GET（查询）。**
> **其中在ES里面PUT和POST的界限并不是很分明，有时候PUT也作为添加。**

## 索引操作
### 创建索引
```java
PUT /ropledata
{
  "settings": { 
    "number_of_shards": "2", 
    "number_of_replicas": "3"
  } 
}

```
### 删除索引
```java
DELETE /ropledata
```
### 修改索引副本数
索引的**分片**是**不允许修改**的，咱们只能修改索引的副本数量，比如想把副本数量修改为2个，只需要执行
```java
PUT ropledata/_settings 
{ 
  "number_of_replicas" : "2" 
}

```
## Mapping 映射
Mapping 是⽤来定义⼀个⽂档 ( document ) ，以及它所包含的属性 ( field ) 是如何存 储和索引的。

### 查询索引的映射
```js
GET /name(索引名)/_mapping
```
### 创建索引并指定映射
```js

PUT /my-index 
{ 
"mappings": { 
	"properties": {
	 "age": { "type": "integer" },
	  "email": { "type": "keyword" }, 
	  "name": { "type": "text" }
}
}
```
### 添加映射
```js
PUT /my-index/_mapping 
{ 
	"properties": { 
	"employee-id": { "type": "keyword", "index": false } } 
}
	
```

### 更新映射
> 我们不能更新已经存在的映射字段，必须创建新的索引进⾏数据迁移

```js
POST _reindex {
"source": { "index": "twitter" },
"dest": { "index": "new_twitter" } 
}
```

## 基础增删改查
#### 插入数据
基础的数据插入时，可以分为两种情况。一种是指定文档的id，一种是不指定
> 如果不指定,ES会帮我们自动生成

```java
%%不指定%%
POST /ropledata/_doc/
{
  "id":1,
  "name":"且听_风吟",
  "page":"https://ropledata.blog.csdn.net",
  "say":"欢迎点赞，收藏，关注，一起学习" 
}

%%指定%%
POST /ropledata/_doc/101 
{
  "id":1,
  "name":"且听_风吟",
  "page":"https://ropledata.blog.csdn.net",
  "say":"欢迎点赞，收藏，关注，一起学习" 
}

```
#### 删除数据
```java
DELETE /ropledata/_doc/101

```

#### 更新数据
ES里的文档是**不可以修改**的，但是**可以覆盖**，所以ES修改数据本质上是对文档的覆盖
ES对数据的修改分为**全局更新**和**局部更新**,局部更新性能优于全局更新
```java
%%全局更新%%
PUT /ropledata/_doc/101
{ 
  "id":1,
  "name":"且听_风吟",
  "page":"https://ropledata.blog.csdn.net",
  "say":"再次欢迎点赞，收藏，关注，一起学习" 
}



```

```java
%%局部更新%%
POST /ropledata/_update/101 
{
  "doc":
  {
    "say":"奥力给"
  } 
}

```
#### 基础查询

> 搜索全部数据（默认展示10条数据）

#### 1. GET全局搜索数据：
```javascript
GET /ropledata/_search
```

#### 2. match_all全局搜索数据，可以加各种条件，比如排序：
```javascript
POST /ropledata/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "id": {
        "order": "asc"
      }
    }
  ]
}

```
**数据结果**![image.png](https://cdn.nlark.com/yuque/0/2022/png/12671612/1663140313075-648b6106-0681-4487-ba6e-e1a330702894.png#averageHue=%23f1f4f8&clientId=u39c27718-e053-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8664d041&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1406&originWidth=2362&originalType=url&ratio=1&rotation=0&showTitle=false&size=909291&status=done&style=none&taskId=u1d90ead0-84f8-44e7-81a0-2232feb7115&title=)

> took：Elasticsearch运行查询需要多长时间(以毫秒为单位)；
> timed_out ：搜索请求是否超时 ；
> _shards 搜索了多少碎片，并对多少碎片成功、失败或跳过进行了细分；
> _max_score 找到最相关的文档的得分；
> hits.total.value ：找到了多少匹配的文档；
> hits.sort ：文档排序后的位置(比如上面查询的1，2，3…) ；
> hits._score：文档的相关性评分(在使用match_all时不适用)

#### 3. 指定id 查
```javascript
GET /ropledata/_doc/101

```

#### 4. 根据关键字搜索
```javascript
GET /ropledata/_search?q=name:"且听风吟，静待花开"

```

#### 5. 高亮查询
```javascript

POST /ropledata/_search
{
  "query": {
    "match": {
      "name": "且听风吟"
    }
  },
  "highlight": {
    "fields": {
      "name": {}
    }
  }
}

%%name这个字段的数据高亮显示%%
```


## DSL查询
**关键字列表**
1. term: 匹配某个属性的值,(一般用于非text字段)
2. keyword：⽂本精确匹配 ( 全部匹配 )
3. terms: 全匹配多个
4. range:范围查询 
	1. gt :大于
	2. gte: 大于等于
	3. lt: 小于
	4. lte: 小于等于
5. exists查询: 是否包含指定字段
6. match: 标准查询,字符串分词匹配,非字符串精确匹配
7. match_phrase: 不忽略空格,将需要匹配的值当作一个整体单词查
8. multi_match:多字段匹配,会分词
9. bool: 合并查询结果
	1. **must**：必须达到must指定的条件,(影响得分)
	2. **must_not**：必须不满足条件 (不影响得分)
	3.  **should**：如果满足,提高得分,不满足,也可以查出
10. filter: 过滤查询,不影响得分,在bool中使用
```js
-- 综合示例
POST /ropledata/_search
{
  "query": {
    "bool": {
      "filter": {
        "range": {
          "id": {
            "gte": 2,
            "lt": 10
          }
        }
      },
      "must_not": {
        "term": {
          "id": 4
        }
      },
      "must": {
        "multi_match": {
         "query": "name", "fields": [ "state", "address"]
        }
      }
    }
  }
}

```

## 聚合函数

聚合：从数据中分组和提取数据。类似于 SQL GROUP BY 和 SQL 聚合函数。 Elasticsearch 可以将命中结果和多个聚合结果同时返回. 可以并列,也可以嵌套
>gender.keyword，意思是对 gender 字段的内容作为整体进行筛选。
```js
--聚合语法

"aggregations" : { 
"<聚合名称 1>" : { 
"<聚合类型>" : { <聚合体内容> }
[,"元数据" : { [] }]? 
[,"aggregations" : { []+ }]? }

[,"聚合名称 2>" : { ""' }]* }

--范例
 
GET bank/_search
{
  "query": {
    "match": {
      "address": "Mill"
    }
  },
  "aggs": {
    "aggGroup": {
      "terms": {
        "field": "age",
        "size": 10
      }
    },
    "ageAvg":{
      "avg": {
        "field": "age"
      }
    },
    "blanceAvg":{
      "avg": {
        "field": "balance"
      }
    }
  }
}
 
```

### 常用函数
1. 数学统计函数
	1. **avg**：平均值
	2.  **max**：最大值
	3. **min**:最小值
	4. **sunm**:求和
2. cardinality: 去重
3. value_count计数统计
4. terms: 词聚合,并安装词数量排序
5. top_hits聚合:一般和terms连用，可以获取到每组前n条数据
6. range:范围查询
```js
POST /ropledata/_search
{
  "aggs": {
    "ropledata": {
      "terms": {
        "field": "id"
      },
      "aggs": {
        "count": {
          "top_hits": {
            "size": 6
          }
        }
      }
    }
  },
  "size": 0
}


```

## 批量操作
### 批量插入
```js
POST _bulk
{ "create" : { "_index" : "ropledata", "_id" : "1009" } }
{"id":9,"name": "且听风吟，静待花开","hobby": "music and movie"}
{ "create" : { "_index" : "ropledata", "_id" : "1010" } }
{"id":10,"name": "且听_风吟","hobby": "music"}
{ "create" : { "_index" : "ropledata", "_id" : "1011" } }
{"id":11,"name": "大数据领域","hobby": "movie"}
{ "create" : { "_index" : "ropledata", "_id" : "1012" } }
{"id":12,"name": "一起学习","hobby": "run"}

```

### 批量查询
```js
POST /ropledata/_mget
{
  "ids": [
    "1010",
    "1011",
    "1012"
  ]
}

```

### 批量更新
```js
POST _bulk
{ "update" : {"_id" : "1011", "_index" : "ropledata"} } { "doc" : {"name" : "批量修改"} }
{ "update" : {"_id" : "1012", "_index" : "ropledata"} } { "doc" : {"name" : "大家好"}}


```

### 批量删除

```js
POST _bulk 
{ "delete" : { "_index" : "ropledata", "_id" : "1011" } } 
{ "delete" : { "_index" : "ropledata", "_id" : "1012" } }

```



# 分词器
## 分词器概念

ES 的⼀个分词器 ( tokenizer ) 接收⼀个字符流，将其分割为独⽴的词元 ( tokens ) ，然后输出 词元流


```js
--查询分词效果
POST _analyze { 
"analyzer": "standard", 
"text": "Do you know why I want to study ELK? 2 3 33""'" }

```

## 分词器安装

**下载分词器,**
注意下载分词器版本要与es版本一致
```url
--下载地址
https://github.com/medcl/elasticsearch-analysis-ik/releases
```

**安装分词器**
分词器安装路径器: ES内部 `plugins`  ⽬录
将下载安装包解压出的文件夹复制到`plugins` 目录
重启es,查询分词器是否安装
```bash
-- /bin/bash目录下
--执行命令,查看es的插件
elasticsearch-plugin list
```
**使用分词器**
ik分词器具有两种模式
1. ik_smart: 智能分词模式
2. ik_max_word: 最大分词模式
```js
--使用检查 切换分词器
POST _analyze { 
"analyzer": "ik_smart",
"text": "⼀颗⼩星星" 
}

```


## 自定义分词

分词器的`自定义分词` 使用有两种模式
1. 文件中自定义分词
2. 使⽤远程服务器⽂件
前缀路径为plugins
**1:文件中自定分词**目录为: `ik(分词器的文件夹称)/config/main.dic
**2:配置文件中指定**,目录为:`ik/config/IKAnalyzer.cfg.xml`
```xml
<comment>IK Analyzer 扩展配置</comment>
<!--用户可以在这里配置自己的扩展字典 -->
<entry key="ext_dict"></entry>
 <!--用户可以在这里配置自己的扩展停止词字典-->
<entry key="ext_stopwords"></entry>
<!--用户可以在这里配置远程扩展字典 -->
<!-- <entry key="remote_ext_dict">words_location</entry> -->
<!--用户可以在这里配置远程扩展停止词字典-->
<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>

```

修改`remote_ext_dict `  属性的值,指定一个远程网站文件的路径,例如nginx,oss的

# 项目中整合

